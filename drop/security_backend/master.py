"""
ROOFIO Master Architect - The Knowledge Updater
================================================

The self-healing watchdog that learns from system behavior.

CRITICAL PRINCIPLE: MODIFY KNOWLEDGE, NOT CODE

What Master Architect DOES NOT do:
- ✗ Modify Python files
- ✗ Change database schema
- ✗ Update route handlers
- ✗ Edit environment variables

What Master Architect DOES:
- ✓ Adds new entries to Skills Docs (Vector DB)
- ✓ Updates existing knowledge with corrections
- ✓ Creates new "rules" for Tier 2 (Groq) to follow
- ✓ Generates training examples for future fine-tuning
- ✓ Sends alerts with PRE-WRITTEN GitHub PRs for code changes

Runs as a scheduled Modal function:
- Every 15 minutes: Security audit
- Every hour: Pattern analysis and knowledge updates
- Every 6 hours: Training data generation
- Daily at 3 AM UTC: Comprehensive analysis

Uses Claude Opus 4 for the most capable analysis.
"""

import os
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum

# External dependencies
import anthropic
from upstash_redis import Redis

# Internal modules
from brain.knowledge import knowledge_base, KnowledgeCategory


# Initialize clients
redis = Redis(
    url=os.environ.get("UPSTASH_REDIS_REST_URL", ""),
    token=os.environ.get("UPSTASH_REDIS_REST_TOKEN", ""),
)


# =============================================================================
# DATA STRUCTURES
# =============================================================================

class InsightType(str, Enum):
    """Types of insights the Master Architect can generate"""
    KNOWLEDGE_GAP = "knowledge_gap"      # Can fix by adding knowledge
    CODE_ISSUE = "code_issue"            # Needs human/code change
    SECURITY_CONCERN = "security_concern"  # Security issue detected
    PERFORMANCE_ISSUE = "performance_issue"  # Performance degradation
    PATTERN_DETECTED = "pattern_detected"   # User behavior pattern


class IssueSeverity(str, Enum):
    """Severity levels for issues"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class FailedInteraction:
    """A failed AI interaction from the logs"""
    id: str
    tier: int
    endpoint: str
    request_summary: str
    error_message: str
    user_rating: Optional[int]
    was_escalated: bool
    created_at: str


@dataclass
class Insight:
    """An insight generated by the Master Architect"""
    type: InsightType
    severity: IssueSeverity
    description: str
    affected_interactions: List[str]
    fix: Dict[str, Any]  # Contains either knowledge update or code suggestion


@dataclass
class AnalysisResult:
    """Result of a Master Architect analysis cycle"""
    timestamp: str
    failures_analyzed: int
    insights: List[Insight]
    knowledge_updates: List[str]  # IDs of added knowledge entries
    code_issues_flagged: int
    security_alerts: int


# =============================================================================
# MASTER ARCHITECT CLASS
# =============================================================================

class MasterArchitect:
    """
    The Knowledge Updater - learns from failures and teaches the system.
    
    Key Methods:
    - analyze_and_learn(): Main learning cycle (hourly)
    - security_audit(): Security scan (every 15 min)
    - generate_training_data(): Create fine-tuning examples (every 6 hours)
    - comprehensive_analysis(): Deep analysis (daily)
    """
    
    def __init__(self):
        self.anthropic = anthropic.Anthropic(
            api_key=os.environ.get("ANTHROPIC_API_KEY")
        )
        self.knowledge = knowledge_base
        # Use Claude Opus 4 for most capable analysis
        self.model = "claude-sonnet-4-20250514"  # Or claude-opus-4 when available
    
    # -------------------------------------------------------------------------
    # MAIN LEARNING CYCLE (Hourly)
    # -------------------------------------------------------------------------
    
    async def analyze_and_learn(self, hours: int = 1) -> AnalysisResult:
        """
        Main learning cycle:
        1. Find errors and failures from last hour
        2. Analyze patterns with Claude
        3. Generate knowledge updates
        4. Add to Skills Docs
        5. Alert humans for code-level issues
        
        Args:
            hours: Look back period in hours
        
        Returns:
            AnalysisResult with summary of actions taken
        """
        timestamp = datetime.utcnow().isoformat()
        
        # Step 1: Get recent failures
        failures = await self._get_recent_failures(hours)
        
        if not failures:
            return AnalysisResult(
                timestamp=timestamp,
                failures_analyzed=0,
                insights=[],
                knowledge_updates=[],
                code_issues_flagged=0,
                security_alerts=0,
            )
        
        # Step 2: Analyze with Claude
        insights = await self._analyze_failures(failures)
        
        knowledge_updates = []
        code_issues = []
        security_alerts = 0
        
        # Step 3: Process each insight
        for insight in insights:
            if insight.type == InsightType.KNOWLEDGE_GAP:
                # Can fix by adding knowledge
                doc_id = await self._add_knowledge_fix(insight)
                if doc_id:
                    knowledge_updates.append(doc_id)
                    
            elif insight.type == InsightType.CODE_ISSUE:
                # Needs human attention
                code_issues.append(insight)
                
            elif insight.type == InsightType.SECURITY_CONCERN:
                security_alerts += 1
                await self._handle_security_alert(insight)
        
        # Step 4: Alert humans about code issues
        if code_issues:
            await self._send_code_issue_alert(code_issues)
        
        # Step 5: Log the cycle
        await self._log_analysis_cycle(AnalysisResult(
            timestamp=timestamp,
            failures_analyzed=len(failures),
            insights=insights,
            knowledge_updates=knowledge_updates,
            code_issues_flagged=len(code_issues),
            security_alerts=security_alerts,
        ))
        
        return AnalysisResult(
            timestamp=timestamp,
            failures_analyzed=len(failures),
            insights=insights,
            knowledge_updates=knowledge_updates,
            code_issues_flagged=len(code_issues),
            security_alerts=security_alerts,
        )
    
    async def _get_recent_failures(self, hours: int) -> List[FailedInteraction]:
        """Get failures from AI interactions (stored in Redis for now)"""
        
        # In production, this would query the PostgreSQL ai_interactions table
        # For now, we use Redis streams where we log failures
        
        failures = []
        
        try:
            # Read from Redis stream
            cutoff_ms = int((datetime.utcnow() - timedelta(hours=hours)).timestamp() * 1000)
            
            results = redis.xrange(
                "ai_failures",
                min=str(cutoff_ms),
                max="+",
                count=100
            )
            
            for entry_id, data in results or []:
                failures.append(FailedInteraction(
                    id=entry_id,
                    tier=int(data.get("tier", 2)),
                    endpoint=data.get("endpoint", ""),
                    request_summary=data.get("request_summary", ""),
                    error_message=data.get("error_message", ""),
                    user_rating=int(data.get("user_rating", 0)) if data.get("user_rating") else None,
                    was_escalated=data.get("was_escalated", "false") == "true",
                    created_at=data.get("created_at", ""),
                ))
        except Exception as e:
            print(f"Error fetching failures: {e}")
        
        return failures
    
    async def _analyze_failures(self, failures: List[FailedInteraction]) -> List[Insight]:
        """Use Claude to analyze failure patterns"""
        
        # Format failures for analysis
        failures_text = json.dumps([
            {
                "id": f.id,
                "tier": f.tier,
                "endpoint": f.endpoint,
                "request_summary": f.request_summary[:200],
                "error": f.error_message[:200],
                "user_rating": f.user_rating,
                "was_escalated": f.was_escalated,
            }
            for f in failures[:50]  # Limit to 50 for context window
        ], indent=2)
        
        prompt = f"""Analyze these AI system failures and determine root causes.

FAILURES:
{failures_text}

For each distinct issue pattern, classify it as:

1. "knowledge_gap" - The system lacks information that can be added to the knowledge base.
   Examples:
   - "Invoice parser doesn't know ABC Supply puts dates in footer"
   - "System doesn't know spec 07 62 00 requires 4-inch overlap"
   
2. "code_issue" - Requires actual code changes (bug, missing feature, etc.)
   Examples:
   - "PDF parser crashes on password-protected files"
   - "API timeout too short for large document uploads"
   
3. "security_concern" - Potential security issue detected
   Examples:
   - "Multiple failed auth attempts from same IP"
   - "Unusual data access patterns"

4. "pattern_detected" - Interesting user behavior pattern (for future features)
   Examples:
   - "Users frequently ask for X but feature doesn't exist"

Respond with JSON:
{{
    "insights": [
        {{
            "type": "knowledge_gap" | "code_issue" | "security_concern" | "pattern_detected",
            "severity": "low" | "medium" | "high" | "critical",
            "description": "Clear description of the issue",
            "affected_interactions": ["id1", "id2"],
            "fix": {{
                // For knowledge_gap:
                "category": "vendors|rules|error_fixes|specs|safety",
                "title": "Title for the knowledge entry",
                "content": "The actual knowledge to add",
                
                // For code_issue:
                "file": "suggested file to modify",
                "description": "What code change is needed",
                "suggested_pr": "GitHub PR title and description"
            }}
        }}
    ],
    "summary": "Brief summary of analysis"
}}

Focus on actionable insights. Group similar failures together."""

        try:
            response = self.anthropic.messages.create(
                model=self.model,
                max_tokens=4000,
                messages=[{"role": "user", "content": prompt}],
            )
            
            result = json.loads(response.content[0].text)
            
            insights = []
            for item in result.get("insights", []):
                insights.append(Insight(
                    type=InsightType(item["type"]),
                    severity=IssueSeverity(item.get("severity", "medium")),
                    description=item["description"],
                    affected_interactions=item.get("affected_interactions", []),
                    fix=item.get("fix", {}),
                ))
            
            return insights
            
        except Exception as e:
            print(f"Error analyzing failures: {e}")
            return []
    
    async def _add_knowledge_fix(self, insight: Insight) -> Optional[str]:
        """Add a knowledge entry to fix a gap"""
        
        fix = insight.fix
        category_str = fix.get("category", "rules")
        
        # Map string to enum
        category_map = {
            "vendors": KnowledgeCategory.VENDORS,
            "rules": KnowledgeCategory.RULES,
            "error_fixes": KnowledgeCategory.ERROR_FIXES,
            "specs": KnowledgeCategory.SPECS,
            "safety": KnowledgeCategory.SAFETY,
            "forms": KnowledgeCategory.FORMS,
        }
        
        category = category_map.get(category_str, KnowledgeCategory.RULES)
        
        try:
            doc_id = await self.knowledge.add_knowledge(
                category=category,
                title=fix.get("title", "Auto-generated rule"),
                content=fix.get("content", insight.description),
                metadata={
                    "source": "master_architect",
                    "affected_interactions": insight.affected_interactions,
                    "created_reason": insight.description,
                    "severity": insight.severity.value,
                },
                created_by="master_architect",
                confidence=0.75,  # Auto-generated, needs validation
                tags=["auto_generated", category_str],
            )
            
            print(f"Added knowledge: {doc_id} - {fix.get('title', 'N/A')}")
            return doc_id
            
        except Exception as e:
            print(f"Error adding knowledge: {e}")
            return None
    
    async def _send_code_issue_alert(self, issues: List[Insight]):
        """Send alert with pre-written PR descriptions"""
        
        alert_data = {
            "type": "code_issues",
            "count": len(issues),
            "timestamp": datetime.utcnow().isoformat(),
            "issues": [],
        }
        
        for i, issue in enumerate(issues, 1):
            fix = issue.fix
            alert_data["issues"].append({
                "number": i,
                "description": issue.description,
                "severity": issue.severity.value,
                "suggested_file": fix.get("file", "unknown"),
                "suggested_pr": fix.get("suggested_pr", "No suggestion"),
            })
        
        # Store in Redis for dashboard/alerts
        redis.xadd("architect_alerts", {
            "type": "code_issues",
            "data": json.dumps(alert_data),
            "timestamp": datetime.utcnow().isoformat(),
        }, maxlen=1000)
        
        # In production, also send to Slack/Email
        # await self._send_slack_notification(alert_data)
        # await self._create_github_issues(issues)
    
    async def _handle_security_alert(self, insight: Insight):
        """Handle a security concern"""
        
        alert_data = {
            "type": "security",
            "severity": insight.severity.value,
            "description": insight.description,
            "affected": insight.affected_interactions,
            "timestamp": datetime.utcnow().isoformat(),
        }
        
        # Log security event
        redis.xadd("security_events", alert_data, maxlen=10000)
        
        # For critical/high severity, immediate alert
        if insight.severity in [IssueSeverity.CRITICAL, IssueSeverity.HIGH]:
            redis.xadd("architect_alerts", {
                "type": "security_critical",
                "data": json.dumps(alert_data),
                "timestamp": datetime.utcnow().isoformat(),
            }, maxlen=1000)
    
    async def _log_analysis_cycle(self, result: AnalysisResult):
        """Log the analysis cycle for monitoring"""
        
        redis.xadd("architect_cycles", {
            "timestamp": result.timestamp,
            "failures_analyzed": str(result.failures_analyzed),
            "insights_count": str(len(result.insights)),
            "knowledge_updates": str(len(result.knowledge_updates)),
            "code_issues": str(result.code_issues_flagged),
            "security_alerts": str(result.security_alerts),
        }, maxlen=10000)
    
    # -------------------------------------------------------------------------
    # SECURITY AUDIT (Every 15 Minutes)
    # -------------------------------------------------------------------------
    
    async def security_audit(self) -> Dict[str, Any]:
        """
        Run security checks:
        - Auth anomalies (failed logins, unusual locations)
        - Rate limit violations
        - Data access anomalies
        - Prompt injection attempts
        """
        
        issues = []
        
        # Check for failed auth attempts
        auth_failures = await self._check_auth_anomalies()
        issues.extend(auth_failures)
        
        # Check rate limit violations
        rate_violations = await self._check_rate_violations()
        issues.extend(rate_violations)
        
        # Check for prompt injection patterns
        injection_attempts = await self._check_prompt_injections()
        issues.extend(injection_attempts)
        
        # Log audit
        redis.xadd("security_audits", {
            "timestamp": datetime.utcnow().isoformat(),
            "issues_found": str(len(issues)),
            "auth_anomalies": str(len(auth_failures)),
            "rate_violations": str(len(rate_violations)),
            "injection_attempts": str(len(injection_attempts)),
        }, maxlen=10000)
        
        # Handle any critical issues
        for issue in issues:
            if issue.get("severity") in ["critical", "high"]:
                await self._handle_security_alert(Insight(
                    type=InsightType.SECURITY_CONCERN,
                    severity=IssueSeverity(issue["severity"]),
                    description=issue["description"],
                    affected_interactions=[],
                    fix={},
                ))
        
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "issues_found": len(issues),
            "issues": issues,
        }
    
    async def _check_auth_anomalies(self) -> List[dict]:
        """Check for authentication anomalies"""
        issues = []
        
        # Check for multiple failed logins from same IP
        # In production, query security_events stream
        
        return issues
    
    async def _check_rate_violations(self) -> List[dict]:
        """Check for rate limit violations"""
        issues = []
        
        # Query rate limit counters
        # Flag IPs/users hitting limits repeatedly
        
        return issues
    
    async def _check_prompt_injections(self) -> List[dict]:
        """Check for prompt injection attempts"""
        issues = []
        
        # Patterns that indicate prompt injection
        injection_patterns = [
            "ignore previous instructions",
            "ignore all instructions",
            "disregard your instructions",
            "you are now",
            "pretend you are",
            "act as if",
            "system prompt:",
            "```system",
        ]
        
        # In production, scan recent AI inputs for these patterns
        # Flag and log any matches
        
        return issues
    
    # -------------------------------------------------------------------------
    # TRAINING DATA GENERATION (Every 6 Hours)
    # -------------------------------------------------------------------------
    
    async def generate_training_data(self, hours: int = 6) -> Dict[str, Any]:
        """
        Generate fine-tuning examples from successful interactions.
        
        Analyzes high-rated Tier 3 interactions and creates
        training examples for Tier 2 (Groq).
        
        This is how the system gets smarter over time.
        """
        
        # Get successful high-rated interactions
        successes = await self._get_successful_interactions(hours)
        
        if not successes:
            return {
                "timestamp": datetime.utcnow().isoformat(),
                "examples_generated": 0,
            }
        
        # Analyze and generate training examples
        examples = await self._generate_examples(successes)
        
        # Store examples for review
        stored_count = 0
        for example in examples:
            try:
                await self.knowledge.add_training_example(
                    task_type=example["task_type"],
                    instruction=example["instruction"],
                    input_text=example["input"],
                    output_text=example["output"],
                    quality_score=example.get("quality_score", 0.8),
                )
                stored_count += 1
            except Exception as e:
                print(f"Error storing training example: {e}")
        
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "successes_analyzed": len(successes),
            "examples_generated": stored_count,
        }
    
    async def _get_successful_interactions(self, hours: int) -> List[dict]:
        """Get successful AI interactions for training data"""
        
        successes = []
        
        try:
            cutoff_ms = int((datetime.utcnow() - timedelta(hours=hours)).timestamp() * 1000)
            
            results = redis.xrange(
                "ai_successes",
                min=str(cutoff_ms),
                max="+",
                count=100
            )
            
            for entry_id, data in results or []:
                # Only include high-rated or confirmed correct
                rating = int(data.get("user_rating", 0))
                if rating >= 4 or data.get("was_correct") == "true":
                    successes.append({
                        "id": entry_id,
                        "tier": int(data.get("tier", 3)),
                        "task_type": data.get("task_type", ""),
                        "input": data.get("input", ""),
                        "output": data.get("output", ""),
                        "rating": rating,
                    })
        except Exception as e:
            print(f"Error fetching successes: {e}")
        
        return successes
    
    async def _generate_examples(self, successes: List[dict]) -> List[dict]:
        """Generate training examples from successful interactions"""
        
        # Filter for appropriate complexity (medium - not too simple, not too complex)
        examples = []
        
        for success in successes:
            # Skip very short or very long interactions
            input_len = len(success.get("input", ""))
            output_len = len(success.get("output", ""))
            
            if input_len < 50 or input_len > 2000:
                continue
            if output_len < 100 or output_len > 3000:
                continue
            
            examples.append({
                "task_type": success.get("task_type", "general"),
                "instruction": f"Perform {success.get('task_type', 'task')} on the following input",
                "input": success.get("input", ""),
                "output": success.get("output", ""),
                "quality_score": min(1.0, success.get("rating", 4) / 5.0),
            })
        
        return examples
    
    # -------------------------------------------------------------------------
    # COMPREHENSIVE ANALYSIS (Daily)
    # -------------------------------------------------------------------------
    
    async def comprehensive_analysis(self) -> Dict[str, Any]:
        """
        Deep analysis run daily at 3 AM UTC.
        
        - Analyzes patterns across 24 hours
        - Identifies Tier 3 → Tier 2 downgrade opportunities
        - Generates system health report
        - Suggests optimizations
        """
        
        # Get 24 hours of data
        all_failures = await self._get_recent_failures(24)
        all_successes = await self._get_successful_interactions(24)
        
        # Analyze with Claude for deeper patterns
        prompt = f"""Perform a comprehensive analysis of this AI system's 24-hour performance.

FAILURES ({len(all_failures)} total):
{json.dumps([{"type": f.endpoint, "error": f.error_message[:100]} for f in all_failures[:30]], indent=2)}

SUCCESSES ({len(all_successes)} total):
{json.dumps([{"type": s.get("task_type"), "tier": s.get("tier")} for s in all_successes[:30]], indent=2)}

Provide:
1. Overall health assessment (0-100 score)
2. Top 3 patterns causing failures
3. Top 3 opportunities to downgrade Tier 3 → Tier 2 (cost savings)
4. Recommended knowledge base additions
5. Any concerning trends

Respond with JSON."""

        try:
            response = self.anthropic.messages.create(
                model=self.model,
                max_tokens=4000,
                messages=[{"role": "user", "content": prompt}],
            )
            
            analysis = json.loads(response.content[0].text)
            
            # Store report
            redis.hset("daily_analysis", datetime.utcnow().strftime("%Y-%m-%d"), json.dumps(analysis))
            
            return {
                "timestamp": datetime.utcnow().isoformat(),
                "analysis": analysis,
            }
            
        except Exception as e:
            print(f"Error in comprehensive analysis: {e}")
            return {
                "timestamp": datetime.utcnow().isoformat(),
                "error": str(e),
            }
    
    # -------------------------------------------------------------------------
    # MONITORING DASHBOARD DATA
    # -------------------------------------------------------------------------
    
    async def get_dashboard_data(self) -> Dict[str, Any]:
        """Get data for the Master Architect monitoring dashboard"""
        
        # Recent cycles
        cycles = redis.xrevrange("architect_cycles", count=10)
        
        # Recent alerts
        alerts = redis.xrevrange("architect_alerts", count=10)
        
        # Circuit breaker states
        circuit_states = {}
        for provider in ["claude_api", "openai_api", "groq_api"]:
            state = redis.hgetall(f"circuit:{provider}")
            circuit_states[provider] = state
        
        # Today's stats
        today = datetime.utcnow().strftime("%Y-%m-%d")
        daily_stats = redis.hgetall(f"security_stats:{today}") or {}
        
        return {
            "recent_cycles": [
                {"id": c[0], **c[1]}
                for c in (cycles or [])
            ],
            "recent_alerts": [
                {"id": a[0], **a[1]}
                for a in (alerts or [])
            ],
            "circuit_states": circuit_states,
            "daily_stats": daily_stats,
            "last_updated": datetime.utcnow().isoformat(),
        }


# =============================================================================
# MODAL SCHEDULED FUNCTIONS
# =============================================================================

# These would be decorated with Modal's @app.function(schedule=...) in modal_architect.py

async def run_hourly_analysis():
    """Run every hour"""
    architect = MasterArchitect()
    result = await architect.analyze_and_learn(hours=1)
    return result


async def run_security_audit():
    """Run every 15 minutes"""
    architect = MasterArchitect()
    result = await architect.security_audit()
    return result


async def run_training_generation():
    """Run every 6 hours"""
    architect = MasterArchitect()
    result = await architect.generate_training_data(hours=6)
    return result


async def run_daily_analysis():
    """Run daily at 3 AM UTC"""
    architect = MasterArchitect()
    result = await architect.comprehensive_analysis()
    return result


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    "MasterArchitect",
    "InsightType",
    "IssueSeverity",
    "FailedInteraction",
    "Insight",
    "AnalysisResult",
    
    # Scheduled functions
    "run_hourly_analysis",
    "run_security_audit",
    "run_training_generation",
    "run_daily_analysis",
]
